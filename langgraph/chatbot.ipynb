{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b52ead6",
   "metadata": {},
   "source": [
    "This notebook demonstrates the creation and usage of a chatbot powered by a generative AI model. Below is an overview of the workflow and the components involved:\n",
    "\n",
    "## 1. Environment Setup\n",
    "The notebook begins by importing necessary modules and loading environment variables using `dotenv`. This ensures that API keys and other sensitive information are securely loaded.\n",
    "\n",
    "## 2. Chatbot Model Initialization\n",
    "The generative AI model (`google_genai:gemini-2.5-pro`) is initialized using the `init_chat_model` function. This model is used to generate responses based on user input.\n",
    "\n",
    "## 3. State Management\n",
    "A custom `State` type is defined using `TypedDict`. This state keeps track of the conversation messages exchanged between the user and the chatbot.\n",
    "\n",
    "## 4. State Graph Construction\n",
    "A `StateGraph` is built to define the flow of the chatbot. The graph includes:\n",
    "- Nodes: Representing the chatbot logic.\n",
    "- Edges: Connecting the start (`START`) and end (`END`) states with the chatbot node.\n",
    "\n",
    "The graph is compiled into a `CompiledStateGraph` object, which can be invoked to process user input and generate responses.\n",
    "\n",
    "## 5. Visualization\n",
    "The structure of the state graph is visualized using `IPython.display` and rendered as an image. This helps in understanding the flow of the chatbot's logic.\n",
    "\n",
    "## 6. Chatbot Interaction\n",
    "The chatbot is tested with a sample user message (`\"What is the capital of France?\"`). The graph processes the input and generates a response (`\"The capital of France is **Paris**.\"`).\n",
    "\n",
    "## 7. Interactive Chatbot (Optional)\n",
    "An interactive chatbot loop is implemented (commented out) to allow continuous conversation with the user. The loop processes user input, updates the state, and generates responses until the user exits.\n",
    "\n",
    "## Key Variables\n",
    "- **START** and **END**: Represent the start and end states of the graph.\n",
    "- **State**: Defines the structure of the chatbot's state.\n",
    "- **builder**: Used to construct the state graph.\n",
    "- **graph**: The compiled state graph for invoking the chatbot.\n",
    "- **messages**: Stores the user input and chatbot responses.\n",
    "- **response**: Contains the chatbot's reply to the user's query.\n",
    "- **state**: Maintains the conversation history during interactive sessions.\n",
    "\n",
    "This notebook provides a structured approach to building and interacting with a generative AI-powered chatbot using state graphs and visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077076cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2693151",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"google_genai:gemini-2.5-pro\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "def chatbot(state: State) -> State:\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot_node\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot_node\")\n",
    "builder.add_edge(\"chatbot_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc501c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    \n",
    "\n",
    "response = graph.invoke({\"messages\": [messages]})\n",
    "\n",
    "# response[\"messages\"]\n",
    "print(\"Bot:\", response[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = None\n",
    "\n",
    "# while True:\n",
    "#     input_msg = input(\"You: \")\n",
    "#     if input_msg.lower() in [\"exit\", \"quit\"]:\n",
    "#         print(\"Exiting chatbot.\")\n",
    "#         break\n",
    "#     if state is None:\n",
    "#         state: State = {\"messages\": [{\"role\": \"user\", \"content\": input_msg}]}\n",
    "#     else:\n",
    "#         state[\"messages\"].append({\"role\": \"user\", \"content\": input_msg})\n",
    "        \n",
    "#     state = graph.invoke(state)\n",
    "#     print(\"Bot:\", state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
